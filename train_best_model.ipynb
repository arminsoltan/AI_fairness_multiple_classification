{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb5af79e-7445-4d8e-8d4e-63acde5a8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torchvision \n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import resnet18, resnet50, resnet152, efficientnet_v2_m, convnext_base, wide_resnet101_2, vgg19_bn, regnet_x_32gf, swin_b, maxvit_t\n",
    "import matplotlib.pyplot as plt\n",
    "import openslide\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1a6d9a-a343-4d4f-8ebf-8c8690d24b5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls /home/ngsci/datasets/brca-psj-path/contest-phase-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "597a07c1-e888-436f-b3f5-1687d3d1dc7b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;32me6c636da7360ec300c0e120316e10d287efe4de78891d43730b5c714b70f542d.dcm\u001b[0m*\n"
     ]
    }
   ],
   "source": [
    "ls /home/ngsci/datasets/covid-psj-xray/v2/xrays/p000000/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279a3171-591d-406d-83f7-79f9d7dc0ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(model):\n",
    "    if len(num_gpus) > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=num_gpus)\n",
    "        model = model.module\n",
    "    model = model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb3d2e2-5e4c-40b0-83a8-298923d216d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_model(model, model_name, dataloaders, criterion, optimizer, num_classes, num_epochs, is_inception, lr, df_train):\n",
    "    since = time.time()\n",
    "    n_splits = 5\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "\n",
    "    # Initialize variables to store results\n",
    "    avg_training_loss = 0.0\n",
    "    avg_validation_loss = 0.0\n",
    "    avg_training_accuracy = 0.0\n",
    "    avg_validation_accuracy = 0.0\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(df_train)):\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Splitting the indices for training and validation\n",
    "        train_biopsy_paths = [biopsy_feature_paths_train[i] for i in train_idx]\n",
    "        train_labels = [labels_train[i] for i in train_idx]\n",
    "        val_biopsy_paths = [biopsy_feature_paths_train[i] for i in val_idx]\n",
    "        val_labels = [labels_train[i] for i in val_idx]\n",
    "\n",
    "        # Creating new datasets for the current fold\n",
    "        train_dataset_fold = BiopsyDataset(train_biopsy_paths, train_labels)\n",
    "        val_dataset_fold = BiopsyDataset(val_biopsy_paths, val_labels)\n",
    "\n",
    "        # Creating dataloaders for the current fold\n",
    "        train_dataloader_fold = DataLoader(train_dataset_fold, batch_size=4, shuffle=True)\n",
    "        val_dataloader_fold = DataLoader(val_dataset_fold, batch_size=4, shuffle=False)\n",
    "\n",
    "        best_loss = float('inf')\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n",
    "\n",
    "            for phase in [\"train\", \"valid\"]:\n",
    "                if phase == \"train\":\n",
    "                    model.train()\n",
    "                else:\n",
    "                    model.eval()\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_corrects = 0\n",
    "\n",
    "                for inputs, labels in dataloaders[phase]:\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    with torch.set_grad_enabled(phase == \"train\"):\n",
    "                        if is_inception and phase == \"train\":\n",
    "                            outputs, aux_outputs = model(inputs)\n",
    "                            loss1 = criterion(outputs, labels)\n",
    "                            loss2 = criterion(aux_outputs, labels)\n",
    "                            loss = loss1 + 0.4 * loss2\n",
    "                        else:\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                        if phase == \"train\":\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    running_loss += loss.item() * inputs.size(0)\n",
    "                    running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "                epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "                epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "                if phase == \"valid\" and epoch_loss < best_loss:\n",
    "                    best_loss = epoch_loss\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            avg_training_loss += epoch_loss if phase == 'train' else avg_training_loss\n",
    "            avg_validation_loss += epoch_loss if phase == 'valid' else avg_validation_loss\n",
    "            avg_training_accuracy += epoch_acc if phase == 'train' else avg_training_accuracy\n",
    "            avg_validation_accuracy += epoch_acc if phase == 'valid' else avg_validation_accuracy\n",
    "\n",
    "    # Loading best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_training_loss /= n_splits\n",
    "    avg_validation_loss /= n_splits\n",
    "    avg_training_accuracy /= n_splits\n",
    "    avg_validation_accuracy /= n_splits\n",
    "\n",
    "    print(f'Average Training Loss: {avg_training_loss:.4f}, Average Validation Loss: {avg_validation_loss:.4f}')\n",
    "    print(f'Average Training Accuracy: {avg_training_accuracy:.4f}, Average Validation Accuracy: {avg_validation_accuracy:.4f}')\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4b104f-bc37-4004-9716-59e06d94834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    if model_name == \"resnet_18\":\n",
    "        model_ft = resnet18(weights=None)\n",
    "        checkpoints = torch.load(\"pretrained_weights/resnet18-f37072fd.pth\")\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    if model_name == \"resnet50\":\n",
    "        model_ft = resnet50(weights=None)\n",
    "        checkpoints = torch.load(\"pretrained_weights/resnet50-0676ba61.pth\")\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    if model_name == \"wide_resnet101\":\n",
    "        \"\"\"Wide Resnet101 V2\"\"\"\n",
    "        model_ft = wide_resnet101_2(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/wide_resnet101_2-d733dc28.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    if model_name == \"resnet152\":\n",
    "        \"\"\"Resnet152\"\"\"\n",
    "        model_ft = resnet152(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/resnet152-394f9c45.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    if model_name == \"efficientnet\":\n",
    "        \"\"\"EFFICIENTNET_V2_M\"\"\"\n",
    "        model_ft = efficientnet_v2_m(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/efficientnet_v2_m-dc08266a.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier[1] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    if model_name == \"convnext\":\n",
    "        \"\"\"convnext_base\"\"\"\n",
    "        model_ft = convnext_base(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/convnext_base-6075fbad.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[2].in_features\n",
    "        model_ft.classifier[2] = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    if model_name == \"vgg\":\n",
    "        \"\"\"VGG19_bn\"\"\"\n",
    "        model_ft = vgg19_bn(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/vgg19_bn-c79401a0.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    if model_name == \"regnet\":\n",
    "        \"\"\"regnet_x_32gf\"\"\"\n",
    "        model_ft = regnet_x_32gf(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/regnet_x_32gf-6eb8fdc6.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    if model_name == \"swin\":\n",
    "        \"\"\"swin_b\"\"\"\n",
    "        model_ft = swin_b(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/swin_b-68c6b09e.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.head.in_features\n",
    "        model_ft.head = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "\n",
    "    if model_name == \"maxvit\":\n",
    "        \"\"\"maxvit\"\"\"\n",
    "        model_ft = maxvit_t(weights=None)\n",
    "        checkpoints = torch.load('pretrained_weights/maxvit_t-bc5ab103.pth')\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[5].in_features\n",
    "        model_ft.classifier[5] = nn.Linear(num_ftrs, num_classes)\n",
    "        \n",
    "    return model_ft, input_size\n",
    "        \n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e6b243-4ccf-49cf-bb8f-8c2031e56615",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideLevelClassifier(nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(SlideLevelClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(num_features, 512)\n",
    "        self.fc2 = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "def pool_features(features, method=\"average\"):\n",
    "    if method == \"average\":\n",
    "        return torch.mean(features, dim=0)\n",
    "    elif method == \"max\":\n",
    "        return torch.max(features, dim=0)[0]\n",
    "    else:\n",
    "        raise valueError(\"Invalid pooling method\")\n",
    "        \n",
    "class BiopsyDataset(Dataset):\n",
    "    def __init__(self, biopsy_feature_paths, labels):\n",
    "        self.biopsy_feature_paths = biopsy_feature_paths\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.biopsy_feature_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "       # Load precomputed features for all slides of the current biopsy\n",
    "        features_list = [torch.load(slide_feature_path) for slide_feature_path in self.biopsy_feature_paths[idx]]\n",
    "\n",
    "        # Instead of stacking, we will average the features for each slide\n",
    "        # This assumes that the feature tensors have the shape [num_tiles, num_features]\n",
    "        # and that you want to average across the num_tiles dimension\n",
    "        slide_features = torch.stack([features.mean(dim=0) for features in features_list])\n",
    "\n",
    "        # Now we can stack since all slide feature tensors will have the same shape\n",
    "        # Then we take the mean across slides to get a single feature vector for the biopsy\n",
    "        biopsy_feature_vector = slide_features.mean(dim=0)\n",
    "\n",
    "        return biopsy_feature_vector, self.labels[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d1984a2-fbc1-4187-a963-adda17ffba4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from openslide import OpenSlide\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3e94501-7a83-42b1-944c-e5676a07dbc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brca_dir = Path().home() / 'datasets' / 'brca-psj-path'\n",
    "ndpi_dir = brca_dir / 'ndpi'\n",
    "clam_train_dir = brca_dir / 'contest-phase-2' / 'clam-preprocessing-train'\n",
    "features_pt_dir = clam_train_dir / 'resnet50-features'/ 'pt_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596e1cd7-7d67-4f7d-9057-cea4616fa366",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'slide_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pt_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(features_pt_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mslide_id\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'slide_id' is not defined"
     ]
    }
   ],
   "source": [
    "pt_features = torch.load(features_pt_dir / f'{slide_id}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "221d72e1-82cb-4b2a-a6c6-47f077d8d866",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_feature_path(slide_id):\n",
    "    return f'{features_pt_dir}/{slide_id}.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "871a58c1-e5f4-4fef-8b9a-96268d0c2955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/home/ngsci/project/Armin/metadata/train.csv\")\n",
    "df_val = pd.read_csv(\"/home/ngsci/project/Armin/metadata/valid.csv\")\n",
    "grouped_train = df_train.groupby(\"biopsy_id\")[\"slide_id\"].apply(lambda x: [get_feature_path(slide) for slide in x])\n",
    "grouped_val = df_val.groupby(\"biopsy_id\")[\"slide_id\"].apply(lambda x: [get_feature_path(slide) for slide in x])\n",
    "biopsy_feature_paths_train = grouped_train.tolist()\n",
    "biopsy_feature_paths_valid = grouped_val.tolist()\n",
    "labels_train = df_train.groupby(\"biopsy_id\").agg({\n",
    "    \"stage\": \"first\"}).reset_index().stage.tolist()\n",
    "labels_valid = df_val.groupby(\"biopsy_id\").agg({\n",
    "    \"stage\": \"first\"}).reset_index().stage.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd34cfe7-a240-44b2-9e65-26278305cd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = BiopsyDataset(biopsy_feature_paths_train, labels_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_dataset = BiopsyDataset(biopsy_feature_paths_valid, labels_valid)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=True)\n",
    "model = SlideLevelClassifier(num_features=1024, num_classes=2)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30d1b18f-dc48-425f-8735-ecbc4bfd38d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:02:35<00:00, 45.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Training Loss: 1.1015, Validation Loss: 0.8560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:04:12<00:00, 46.98s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Training Loss: 0.7755, Validation Loss: 0.7032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:03:28<00:00, 46.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Training Loss: 0.7063, Validation Loss: 0.6811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:01:34<00:00, 45.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Training Loss: 0.6837, Validation Loss: 0.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:01:17<00:00, 44.85s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Training Loss: 0.6694, Validation Loss: 0.7030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:02:44<00:00, 45.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/20], Training Loss: 0.6633, Validation Loss: 0.6902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:02:39<00:00, 45.85s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Training Loss: 0.6558, Validation Loss: 0.6735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:02:02<00:00, 45.40s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Training Loss: 0.6486, Validation Loss: 0.6925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:01:52<00:00, 45.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Training Loss: 0.6399, Validation Loss: 0.6913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:01:09<00:00, 44.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/20], Training Loss: 0.6335, Validation Loss: 0.6923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:01:21<00:00, 44.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Training Loss: 0.6255, Validation Loss: 0.6765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [1:00:17<00:00, 44.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Training Loss: 0.6189, Validation Loss: 0.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [57:41<00:00, 42.22s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Training Loss: 0.6148, Validation Loss: 0.6792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [57:21<00:00, 41.97s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Training Loss: 0.6065, Validation Loss: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [56:38<00:00, 41.45s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Training Loss: 0.6007, Validation Loss: 0.7226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [55:56<00:00, 40.94s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Training Loss: 0.5913, Validation Loss: 0.7169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [55:26<00:00, 40.57s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Training Loss: 0.5891, Validation Loss: 0.7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [54:23<00:00, 39.80s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Training Loss: 0.5825, Validation Loss: 0.7067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [54:31<00:00, 39.89s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/20], Training Loss: 0.5835, Validation Loss: 0.7137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [55:16<00:00, 40.44s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Training Loss: 0.5722, Validation Loss: 0.7459\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "best_val_loss = 1000000\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_features, batch_labels in tqdm(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    training_loss = running_loss / len(train_dataloader)\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_features, val_labels in val_dataloader:\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            running_val_loss += val_loss.item()\n",
    "    validation_loss = running_val_loss / len(val_dataloader)\n",
    "    \n",
    "    if validation_loss < best_val_loss:\n",
    "        best_val_loss = validation_loss\n",
    "        torch.save(model.state_dict(), \"/home/ngsci/project/Armin/saved_models/breast_cancer_attention.pth\")\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Training Loss: {training_loss:.4f}, Validation Loss: {validation_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d988799-33fd-455d-92f4-3ac305f0e18c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"/home/ngsci/project/Armin/saved_models/breast_cancer_attention_end.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "313b361f-8e67-42d5-93b1-f5cf8f449c77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/home/ngsci/project/Armin/metadata/test.csv\")\n",
    "grouped_test = df_test.groupby(\"biopsy_id\")[\"slide_id\"].apply(lambda x: [get_feature_path(slide) for slide in x])\n",
    "biopsy_feature_paths_test = grouped_test.tolist()\n",
    "labels_test = df_test.groupby(\"biopsy_id\").agg({\n",
    "    \"stage\": \"first\"}).reset_index().stage.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87066b10-735c-4952-bbe9-ba5dea1bad55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = BiopsyDataset(biopsy_feature_paths_test, labels_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "669cbf23-e035-4dd1-bda0-5deb21f47a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>biopsy_id</th>\n",
       "      <th>stage</th>\n",
       "      <th>race</th>\n",
       "      <th>slide_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>00c619a9-7f7d-4d18-bd87-7c2bd482fc05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1e0502bb-e0c9-45a8-99d9-212f945de9c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>00c619a9-7f7d-4d18-bd87-7c2bd482fc05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>d6cf5a07-db91-45af-83b5-14531f50c42f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>02b059c2-5445-453b-9ba6-636812b5089d</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82467cf2-671b-4e19-910d-eb0a49570f7e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>02b059c2-5445-453b-9ba6-636812b5089d</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>b13358ab-487b-4352-a4c7-810b170b7b64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366</td>\n",
       "      <td>085c5190-e25e-4443-b53f-483121f711ca</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>376d279c-03d1-437d-beaf-6fd58d9334db</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             biopsy_id  stage  race   \n",
       "0          21  00c619a9-7f7d-4d18-bd87-7c2bd482fc05      0     1  \\\n",
       "1          22  00c619a9-7f7d-4d18-bd87-7c2bd482fc05      0     1   \n",
       "2         128  02b059c2-5445-453b-9ba6-636812b5089d      0     4   \n",
       "3         129  02b059c2-5445-453b-9ba6-636812b5089d      0     4   \n",
       "4         366  085c5190-e25e-4443-b53f-483121f711ca      0     1   \n",
       "\n",
       "                               slide_id  \n",
       "0  1e0502bb-e0c9-45a8-99d9-212f945de9c8  \n",
       "1  d6cf5a07-db91-45af-83b5-14531f50c42f  \n",
       "2  82467cf2-671b-4e19-910d-eb0a49570f7e  \n",
       "3  b13358ab-487b-4352-a4c7-810b170b7b64  \n",
       "4  376d279c-03d1-437d-beaf-6fd58d9334db  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a3ec4ee-d780-461e-897b-24000046b98d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for SlideLevelClassifier:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([4, 512]) from checkpoint, the shape in current model is torch.Size([2, 512]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m SlideLevelClassifier(num_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/ngsci/project/Armin/saved_models/breast_cancer_attention_end.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for SlideLevelClassifier:\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([4, 512]) from checkpoint, the shape in current model is torch.Size([2, 512]).\n\tsize mismatch for fc2.bias: copying a param with shape torch.Size([4]) from checkpoint, the shape in current model is torch.Size([2])."
     ]
    }
   ],
   "source": [
    "model = SlideLevelClassifier(num_features=1024, num_classes=2)\n",
    "model.load_state_dict(torch.load(\"/home/ngsci/project/Armin/saved_models/breast_cancer_attention_end.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0732b422-35cf-4fc6-a10a-a073dc3687e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Storage for the results\n",
    "results = []\n",
    "\n",
    "# Iterate over the test data\n",
    "for i, (inputs, _) in enumerate(test_dataloader):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        # Assuming you're doing classification and you want to get the class with the maximum score\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        results.extend(preds.cpu().numpy())\n",
    "\n",
    "# Assuming biopsy_ids are unique and their order in labels_test corresponds to the order in the DataLoader\n",
    "biopsy_ids = df_test['biopsy_id'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "305fad13-ed7c-4721-b5b7-9c9614434b16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>biopsy_id</th>\n",
       "      <th>stage</th>\n",
       "      <th>race</th>\n",
       "      <th>slide_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "      <td>00c619a9-7f7d-4d18-bd87-7c2bd482fc05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1e0502bb-e0c9-45a8-99d9-212f945de9c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>00c619a9-7f7d-4d18-bd87-7c2bd482fc05</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>d6cf5a07-db91-45af-83b5-14531f50c42f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>02b059c2-5445-453b-9ba6-636812b5089d</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>82467cf2-671b-4e19-910d-eb0a49570f7e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129</td>\n",
       "      <td>02b059c2-5445-453b-9ba6-636812b5089d</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>b13358ab-487b-4352-a4c7-810b170b7b64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366</td>\n",
       "      <td>085c5190-e25e-4443-b53f-483121f711ca</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>376d279c-03d1-437d-beaf-6fd58d9334db</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                             biopsy_id  stage  race   \n",
       "0          21  00c619a9-7f7d-4d18-bd87-7c2bd482fc05      0     1  \\\n",
       "1          22  00c619a9-7f7d-4d18-bd87-7c2bd482fc05      0     1   \n",
       "2         128  02b059c2-5445-453b-9ba6-636812b5089d      0     4   \n",
       "3         129  02b059c2-5445-453b-9ba6-636812b5089d      0     4   \n",
       "4         366  085c5190-e25e-4443-b53f-483121f711ca      0     1   \n",
       "\n",
       "                               slide_id  \n",
       "0  1e0502bb-e0c9-45a8-99d9-212f945de9c8  \n",
       "1  d6cf5a07-db91-45af-83b5-14531f50c42f  \n",
       "2  82467cf2-671b-4e19-910d-eb0a49570f7e  \n",
       "3  b13358ab-487b-4352-a4c7-810b170b7b64  \n",
       "4  376d279c-03d1-437d-beaf-6fd58d9334db  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe6a7822-91a4-474f-a44d-6ba117aa36ca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'biopsy_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[1;32m      2\u001b[0m result_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbiopsy_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mbiopsy_ids\u001b[49m,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_stage\u001b[39m\u001b[38;5;124m'\u001b[39m: results,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual_stage\u001b[39m\u001b[38;5;124m'\u001b[39m: df_test\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiopsy_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mstage\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_test\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiopsy_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mrace\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslide_id\u001b[39m\u001b[38;5;124m'\u001b[39m: df_test\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbiopsy_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mslide_id\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m})\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mslide_id\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      8\u001b[0m })\n\u001b[1;32m     10\u001b[0m result_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions/predictions_attention.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'biopsy_ids' is not defined"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "result_df = pd.DataFrame({\n",
    "    'biopsy_id': biopsy_ids,\n",
    "    'pred_stage': results,\n",
    "    'actual_stage': df_test.groupby(\"biopsy_id\").agg({\"stage\": \"first\"}).reset_index().stage.tolist(),\n",
    "    \"race\": df_test.groupby(\"biopsy_id\").agg({\"race\": \"first\"}).reset_index().race.tolist(),\n",
    "    'slide_id': df_test.groupby(\"biopsy_id\").agg({\"stage\": \"first\", 'slide_id': \"first\"}).reset_index().slide_id.tolist()\n",
    "})\n",
    "\n",
    "result_df.to_csv('predictions/predictions_attention.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9ce61ab7-cf0b-4fde-add8-da2c5e490125",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"/\", \"home\", \"ngsci\", \"project\", \"Armin\", \"metadata\")\n",
    "\n",
    "num_classes = 2\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "feature_extract = False\n",
    "num_gpus = [i for i in range(torch.cuda.device_count())]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if len(num_gpus) > 1:\n",
    "    print(\"We are using {} gpus\".format(len(num_gpus)))\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(str(x) for x in num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efeceb19-4976-4c95-a37f-f8ba219b5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"/\", \"home\", \"ngsci\", \"project\", \"Armin\", \"metadata2\")\n",
    "num_classes = 3\n",
    "batch_size = 32\n",
    "num_epochs = 20\n",
    "feature_extract = False\n",
    "num_gpus = [i for i in range(torch.cuda.device_count())]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if len(num_gpus) > 1:\n",
    "    print(\"We are using {} gpus\".format(len(num_gpus)))\n",
    "    os.environ[\"CUDA_VISISBLE_DEVICES\"] = ','.join(str(x) for x in num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9017ca2-cdd0-41a4-a7bb-533190d8dd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 1.2084 Acc: 0.3402\n",
      "valid Loss: 0.9554 Acc: 0.5843\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.8233 Acc: 0.6513\n",
      "valid Loss: 0.8522 Acc: 0.6050\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.7624 Acc: 0.6595\n",
      "valid Loss: 0.8319 Acc: 0.5977\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.7356 Acc: 0.6742\n",
      "valid Loss: 0.8100 Acc: 0.6060\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.7258 Acc: 0.6738\n",
      "valid Loss: 0.8281 Acc: 0.5977\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.7171 Acc: 0.6840\n",
      "valid Loss: 0.8165 Acc: 0.6101\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.7111 Acc: 0.6812\n",
      "valid Loss: 0.8015 Acc: 0.6101\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.6926 Acc: 0.6979\n",
      "valid Loss: 0.7980 Acc: 0.6091\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.6831 Acc: 0.6983\n",
      "valid Loss: 0.8043 Acc: 0.6081\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.6742 Acc: 0.7052\n",
      "valid Loss: 0.8332 Acc: 0.6060\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.6644 Acc: 0.7102\n",
      "valid Loss: 0.8264 Acc: 0.6122\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.6565 Acc: 0.7152\n",
      "valid Loss: 0.8193 Acc: 0.6029\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.6477 Acc: 0.7187\n",
      "valid Loss: 0.8421 Acc: 0.6060\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.6408 Acc: 0.7230\n",
      "valid Loss: 0.8364 Acc: 0.5998\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.6311 Acc: 0.7291\n",
      "valid Loss: 0.8549 Acc: 0.6029\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.6286 Acc: 0.7217\n",
      "valid Loss: 0.8496 Acc: 0.6122\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.6189 Acc: 0.7355\n",
      "valid Loss: 0.8651 Acc: 0.6060\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.6138 Acc: 0.7386\n",
      "valid Loss: 0.8578 Acc: 0.6091\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.5960 Acc: 0.7508\n",
      "valid Loss: 0.8847 Acc: 0.6008\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.5933 Acc: 0.7482\n",
      "valid Loss: 0.8892 Acc: 0.6060\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.7977 Acc: 0.6345\n",
      "valid Loss: 0.8426 Acc: 0.5698\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.7521 Acc: 0.6529\n",
      "valid Loss: 0.9118 Acc: 0.5822\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.7315 Acc: 0.6707\n",
      "valid Loss: 0.8358 Acc: 0.6060\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.7028 Acc: 0.6827\n",
      "valid Loss: 0.9428 Acc: 0.5957\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.6930 Acc: 0.6927\n",
      "valid Loss: 0.7991 Acc: 0.6287\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.6742 Acc: 0.7005\n",
      "valid Loss: 0.8961 Acc: 0.5905\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.6606 Acc: 0.7129\n",
      "valid Loss: 0.9713 Acc: 0.6205\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.6468 Acc: 0.7119\n",
      "valid Loss: 0.8500 Acc: 0.5946\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.6355 Acc: 0.7185\n",
      "valid Loss: 0.9479 Acc: 0.5471\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.6175 Acc: 0.7306\n",
      "valid Loss: 0.9464 Acc: 0.5977\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.6039 Acc: 0.7345\n",
      "valid Loss: 1.0092 Acc: 0.5481\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.5939 Acc: 0.7421\n",
      "valid Loss: 0.9676 Acc: 0.5750\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.5905 Acc: 0.7443\n",
      "valid Loss: 0.9067 Acc: 0.6112\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.5652 Acc: 0.7560\n",
      "valid Loss: 0.8996 Acc: 0.6019\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.5554 Acc: 0.7592\n",
      "valid Loss: 1.0502 Acc: 0.5926\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.5452 Acc: 0.7666\n",
      "valid Loss: 1.0034 Acc: 0.6132\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.5293 Acc: 0.7737\n",
      "valid Loss: 1.0219 Acc: 0.6112\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.5248 Acc: 0.7750\n",
      "valid Loss: 1.0009 Acc: 0.6091\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.5072 Acc: 0.7837\n",
      "valid Loss: 1.3406 Acc: 0.5522\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.4875 Acc: 0.7936\n",
      "valid Loss: 1.1613 Acc: 0.5667\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.7929 Acc: 0.6401\n",
      "valid Loss: 0.8425 Acc: 0.6174\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.7357 Acc: 0.6697\n",
      "valid Loss: 0.8036 Acc: 0.6153\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.6938 Acc: 0.6936\n",
      "valid Loss: 0.8504 Acc: 0.6153\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.6602 Acc: 0.7067\n",
      "valid Loss: 0.8283 Acc: 0.6225\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.6204 Acc: 0.7317\n",
      "valid Loss: 0.8848 Acc: 0.6360\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.6014 Acc: 0.7395\n",
      "valid Loss: 0.8487 Acc: 0.6101\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.5602 Acc: 0.7587\n",
      "valid Loss: 1.0621 Acc: 0.6091\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.5389 Acc: 0.7684\n",
      "valid Loss: 1.0308 Acc: 0.5791\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.4967 Acc: 0.7873\n",
      "valid Loss: 0.9702 Acc: 0.6132\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.4738 Acc: 0.8034\n",
      "valid Loss: 1.1547 Acc: 0.5760\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.4438 Acc: 0.8196\n",
      "valid Loss: 0.9891 Acc: 0.6225\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.4187 Acc: 0.8255\n",
      "valid Loss: 1.1400 Acc: 0.5946\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.3858 Acc: 0.8424\n",
      "valid Loss: 1.3246 Acc: 0.5853\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.3725 Acc: 0.8467\n",
      "valid Loss: 1.5269 Acc: 0.5564\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.3479 Acc: 0.8595\n",
      "valid Loss: 1.4874 Acc: 0.5874\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.3326 Acc: 0.8665\n",
      "valid Loss: 1.5296 Acc: 0.6039\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.3212 Acc: 0.8699\n",
      "valid Loss: 1.7049 Acc: 0.5357\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.3157 Acc: 0.8745\n",
      "valid Loss: 1.6274 Acc: 0.6050\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.2869 Acc: 0.8875\n",
      "valid Loss: 1.6976 Acc: 0.5926\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.2815 Acc: 0.8865\n",
      "valid Loss: 1.5480 Acc: 0.6081\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.8025 Acc: 0.6296\n",
      "valid Loss: 0.9512 Acc: 0.5946\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.7717 Acc: 0.6472\n",
      "valid Loss: 0.8314 Acc: 0.5605\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.7462 Acc: 0.6601\n",
      "valid Loss: 0.8078 Acc: 0.6122\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.7214 Acc: 0.6722\n",
      "valid Loss: 0.8093 Acc: 0.6246\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.7076 Acc: 0.6802\n",
      "valid Loss: 1.0127 Acc: 0.6008\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.6972 Acc: 0.6936\n",
      "valid Loss: 0.8004 Acc: 0.6132\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.6906 Acc: 0.6932\n",
      "valid Loss: 0.8877 Acc: 0.6205\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.6726 Acc: 0.6933\n",
      "valid Loss: 0.8216 Acc: 0.6287\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.6545 Acc: 0.7141\n",
      "valid Loss: 0.8840 Acc: 0.5957\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.6448 Acc: 0.7197\n",
      "valid Loss: 0.9631 Acc: 0.5977\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.6410 Acc: 0.7184\n",
      "valid Loss: 0.9245 Acc: 0.6008\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.6283 Acc: 0.7250\n",
      "valid Loss: 0.8635 Acc: 0.6132\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.6030 Acc: 0.7397\n",
      "valid Loss: 0.9273 Acc: 0.5946\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.6039 Acc: 0.7410\n",
      "valid Loss: 1.0857 Acc: 0.5812\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.5928 Acc: 0.7397\n",
      "valid Loss: 1.0019 Acc: 0.6081\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.5734 Acc: 0.7522\n",
      "valid Loss: 0.9244 Acc: 0.5957\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.5575 Acc: 0.7626\n",
      "valid Loss: 1.0792 Acc: 0.5667\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.5497 Acc: 0.7627\n",
      "valid Loss: 1.0970 Acc: 0.5429\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.5289 Acc: 0.7730\n",
      "valid Loss: 1.2190 Acc: 0.5440\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.5229 Acc: 0.7714\n",
      "valid Loss: 1.0558 Acc: 0.5874\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.7894 Acc: 0.6465\n",
      "valid Loss: 0.8016 Acc: 0.6360\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.7242 Acc: 0.6751\n",
      "valid Loss: 0.8488 Acc: 0.6019\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.6782 Acc: 0.6961\n",
      "valid Loss: 0.8138 Acc: 0.6339\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.6424 Acc: 0.7193\n",
      "valid Loss: 0.9020 Acc: 0.6122\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.6004 Acc: 0.7400\n",
      "valid Loss: 0.9666 Acc: 0.5936\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.5585 Acc: 0.7626\n",
      "valid Loss: 1.0435 Acc: 0.5739\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.5104 Acc: 0.7886\n",
      "valid Loss: 1.0966 Acc: 0.5884\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.4808 Acc: 0.7981\n",
      "valid Loss: 1.1587 Acc: 0.5863\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.4395 Acc: 0.8150\n",
      "valid Loss: 1.1510 Acc: 0.5729\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.4104 Acc: 0.8314\n",
      "valid Loss: 1.1948 Acc: 0.5822\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.3647 Acc: 0.8506\n",
      "valid Loss: 1.3648 Acc: 0.6132\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.3617 Acc: 0.8544\n",
      "valid Loss: 1.1678 Acc: 0.5884\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.3245 Acc: 0.8666\n",
      "valid Loss: 1.3833 Acc: 0.5884\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.3202 Acc: 0.8731\n",
      "valid Loss: 1.3599 Acc: 0.5739\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.2985 Acc: 0.8794\n",
      "valid Loss: 1.6391 Acc: 0.5936\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.2816 Acc: 0.8876\n",
      "valid Loss: 1.6247 Acc: 0.5998\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.2775 Acc: 0.8856\n",
      "valid Loss: 1.7950 Acc: 0.5843\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.2684 Acc: 0.8941\n",
      "valid Loss: 1.5119 Acc: 0.5936\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.2561 Acc: 0.8986\n",
      "valid Loss: 1.6631 Acc: 0.5781\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.2511 Acc: 0.8997\n",
      "valid Loss: 1.5525 Acc: 0.5791\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.8083 Acc: 0.6337\n",
      "valid Loss: 0.8165 Acc: 0.6091\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.7729 Acc: 0.6487\n",
      "valid Loss: 0.8018 Acc: 0.6143\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.7419 Acc: 0.6572\n",
      "valid Loss: 0.7971 Acc: 0.6370\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.7174 Acc: 0.6749\n",
      "valid Loss: 0.8087 Acc: 0.6277\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.6874 Acc: 0.6912\n",
      "valid Loss: 0.8388 Acc: 0.6432\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.6627 Acc: 0.7071\n",
      "valid Loss: 0.8271 Acc: 0.6567\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 0.7205\n",
      "valid Loss: 0.8303 Acc: 0.6587\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.5926 Acc: 0.7429\n",
      "valid Loss: 0.9419 Acc: 0.5988\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.5650 Acc: 0.7537\n",
      "valid Loss: 0.9843 Acc: 0.6112\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.5236 Acc: 0.7785\n",
      "valid Loss: 1.1558 Acc: 0.5874\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.4835 Acc: 0.7945\n",
      "valid Loss: 1.1714 Acc: 0.6205\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.4631 Acc: 0.8104\n",
      "valid Loss: 1.2840 Acc: 0.5791\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.4376 Acc: 0.8201\n",
      "valid Loss: 1.3109 Acc: 0.5967\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.4116 Acc: 0.8277\n",
      "valid Loss: 1.4170 Acc: 0.5998\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.3856 Acc: 0.8428\n",
      "valid Loss: 1.2956 Acc: 0.6194\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.3794 Acc: 0.8431\n",
      "valid Loss: 1.4370 Acc: 0.5957\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.3491 Acc: 0.8561\n",
      "valid Loss: 1.6572 Acc: 0.6143\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.3334 Acc: 0.8646\n",
      "valid Loss: 1.3934 Acc: 0.6246\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.3238 Acc: 0.8705\n",
      "valid Loss: 1.5960 Acc: 0.5708\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.3135 Acc: 0.8744\n",
      "valid Loss: 1.4952 Acc: 0.6225\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.8037 Acc: 0.6355\n",
      "valid Loss: 0.8173 Acc: 0.6112\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.7666 Acc: 0.6515\n",
      "valid Loss: 0.8150 Acc: 0.6070\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.7509 Acc: 0.6608\n",
      "valid Loss: 0.8002 Acc: 0.6081\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.7316 Acc: 0.6685\n",
      "valid Loss: 0.8102 Acc: 0.5874\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.7188 Acc: 0.6823\n",
      "valid Loss: 0.8298 Acc: 0.5998\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.7110 Acc: 0.6850\n",
      "valid Loss: 0.9483 Acc: 0.5988\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.6950 Acc: 0.6893\n",
      "valid Loss: 0.8308 Acc: 0.5977\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.6792 Acc: 0.7013\n",
      "valid Loss: 0.8284 Acc: 0.5626\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.6763 Acc: 0.7033\n",
      "valid Loss: 0.8456 Acc: 0.5915\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.6616 Acc: 0.7131\n",
      "valid Loss: 0.8162 Acc: 0.6184\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 0.7162\n",
      "valid Loss: 0.8811 Acc: 0.6101\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.6465 Acc: 0.7190\n",
      "valid Loss: 0.7984 Acc: 0.6050\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.6342 Acc: 0.7218\n",
      "valid Loss: 0.8218 Acc: 0.6422\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.6192 Acc: 0.7276\n",
      "valid Loss: 0.9426 Acc: 0.5863\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.6100 Acc: 0.7357\n",
      "valid Loss: 1.1055 Acc: 0.5471\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.5925 Acc: 0.7400\n",
      "valid Loss: 1.1962 Acc: 0.5998\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.5957 Acc: 0.7414\n",
      "valid Loss: 1.0918 Acc: 0.6381\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.5785 Acc: 0.7532\n",
      "valid Loss: 0.9201 Acc: 0.6205\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.5622 Acc: 0.7622\n",
      "valid Loss: 1.0170 Acc: 0.5988\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.5627 Acc: 0.7597\n",
      "valid Loss: 0.9593 Acc: 0.6081\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.7747 Acc: 0.6524\n",
      "valid Loss: 0.8682 Acc: 0.6184\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.6934 Acc: 0.6953\n",
      "valid Loss: 0.8560 Acc: 0.6163\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.6280 Acc: 0.7230\n",
      "valid Loss: 0.9067 Acc: 0.6112\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.5922 Acc: 0.7484\n",
      "valid Loss: 0.8627 Acc: 0.6029\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.5316 Acc: 0.7733\n",
      "valid Loss: 0.9415 Acc: 0.6143\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.4807 Acc: 0.8032\n",
      "valid Loss: 1.0491 Acc: 0.5719\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.4349 Acc: 0.8207\n",
      "valid Loss: 1.1921 Acc: 0.5781\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.3901 Acc: 0.8407\n",
      "valid Loss: 1.3442 Acc: 0.5667\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.3564 Acc: 0.8548\n",
      "valid Loss: 1.4659 Acc: 0.6039\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.3240 Acc: 0.8679\n",
      "valid Loss: 1.6048 Acc: 0.5915\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.2942 Acc: 0.8839\n",
      "valid Loss: 1.8511 Acc: 0.5988\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.2896 Acc: 0.8875\n",
      "valid Loss: 1.8505 Acc: 0.5595\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.2683 Acc: 0.8952\n",
      "valid Loss: 1.5083 Acc: 0.5843\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.2418 Acc: 0.9038\n",
      "valid Loss: 1.7916 Acc: 0.6008\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.2347 Acc: 0.9053\n",
      "valid Loss: 1.9925 Acc: 0.5832\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.2363 Acc: 0.9074\n",
      "valid Loss: 1.8768 Acc: 0.5791\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.2179 Acc: 0.9153\n",
      "valid Loss: 1.9313 Acc: 0.5688\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.2153 Acc: 0.9161\n",
      "valid Loss: 1.9016 Acc: 0.5915\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.2034 Acc: 0.9185\n",
      "valid Loss: 2.0106 Acc: 0.5698\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.1820 Acc: 0.9274\n",
      "valid Loss: 2.1051 Acc: 0.5915\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.8197 Acc: 0.6324\n",
      "valid Loss: 0.8197 Acc: 0.5946\n",
      "\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.7974 Acc: 0.6341\n",
      "valid Loss: 0.7863 Acc: 0.6215\n",
      "\n",
      "Epoch 3/20\n",
      "----------\n",
      "train Loss: 0.7813 Acc: 0.6433\n",
      "valid Loss: 0.7903 Acc: 0.6101\n",
      "\n",
      "Epoch 4/20\n",
      "----------\n",
      "train Loss: 0.7696 Acc: 0.6490\n",
      "valid Loss: 0.7951 Acc: 0.6060\n",
      "\n",
      "Epoch 5/20\n",
      "----------\n",
      "train Loss: 0.7556 Acc: 0.6521\n",
      "valid Loss: 0.8035 Acc: 0.5998\n",
      "\n",
      "Epoch 6/20\n",
      "----------\n",
      "train Loss: 0.7490 Acc: 0.6574\n",
      "valid Loss: 0.8004 Acc: 0.6060\n",
      "\n",
      "Epoch 7/20\n",
      "----------\n",
      "train Loss: 0.7348 Acc: 0.6671\n",
      "valid Loss: 0.8130 Acc: 0.6205\n",
      "\n",
      "Epoch 8/20\n",
      "----------\n",
      "train Loss: 0.7219 Acc: 0.6724\n",
      "valid Loss: 0.7868 Acc: 0.6319\n",
      "\n",
      "Epoch 9/20\n",
      "----------\n",
      "train Loss: 0.7073 Acc: 0.6772\n",
      "valid Loss: 0.8125 Acc: 0.6184\n",
      "\n",
      "Epoch 10/20\n",
      "----------\n",
      "train Loss: 0.7063 Acc: 0.6844\n",
      "valid Loss: 0.8066 Acc: 0.6329\n",
      "\n",
      "Epoch 11/20\n",
      "----------\n",
      "train Loss: 0.6924 Acc: 0.6931\n",
      "valid Loss: 0.7862 Acc: 0.6122\n",
      "\n",
      "Epoch 12/20\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 0.7022\n",
      "valid Loss: 0.7927 Acc: 0.6339\n",
      "\n",
      "Epoch 13/20\n",
      "----------\n",
      "train Loss: 0.6643 Acc: 0.7035\n",
      "valid Loss: 0.8264 Acc: 0.6319\n",
      "\n",
      "Epoch 14/20\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 0.7202\n",
      "valid Loss: 0.7560 Acc: 0.6691\n",
      "\n",
      "Epoch 15/20\n",
      "----------\n",
      "train Loss: 0.6377 Acc: 0.7205\n",
      "valid Loss: 0.8662 Acc: 0.6412\n",
      "\n",
      "Epoch 16/20\n",
      "----------\n",
      "train Loss: 0.6208 Acc: 0.7277\n",
      "valid Loss: 0.8350 Acc: 0.6639\n",
      "\n",
      "Epoch 17/20\n",
      "----------\n",
      "train Loss: 0.6073 Acc: 0.7377\n",
      "valid Loss: 0.8229 Acc: 0.6505\n",
      "\n",
      "Epoch 18/20\n",
      "----------\n",
      "train Loss: 0.5864 Acc: 0.7475\n",
      "valid Loss: 0.9910 Acc: 0.6163\n",
      "\n",
      "Epoch 19/20\n",
      "----------\n",
      "train Loss: 0.5774 Acc: 0.7523\n",
      "valid Loss: 0.9308 Acc: 0.6370\n",
      "\n",
      "Epoch 20/20\n",
      "----------\n",
      "train Loss: 0.5613 Acc: 0.7569\n",
      "valid Loss: 0.9994 Acc: 0.6339\n",
      "\n",
      "Epoch 1/20\n",
      "----------\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/datasets/folder.py\", line 231, in __getitem__\n    sample = self.transform(sample)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 361, in forward\n    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 490, in resize\n    return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py\", line 250, in resize\n    return img.resize(tuple(size[::-1]), interpolation)\n  File \"/opt/venv/default/lib/python3.10/site-packages/PIL/Image.py\", line 2193, in resize\n    return self._new(self.im.resize(size, resample, box))\nValueError: height and width must be > 0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m optimizer_ft \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdamW(params_to_update, lr\u001b[38;5;241m=\u001b[39mlr_)\n\u001b[1;32m     58\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m---> 59\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_ft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 18\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, model_name, dataloaders, criterion, optimizer, num_classes, num_epochs, is_inception, lr)\u001b[0m\n\u001b[1;32m     15\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     16\u001b[0m running_corrects \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[1;32m     19\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     20\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/datasets/folder.py\", line 231, in __getitem__\n    sample = self.transform(sample)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 361, in forward\n    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 490, in resize\n    return F_pil.resize(img, size=output_size, interpolation=pil_interpolation)\n  File \"/opt/venv/default/lib/python3.10/site-packages/torchvision/transforms/_functional_pil.py\", line 250, in resize\n    return img.resize(tuple(size[::-1]), interpolation)\n  File \"/opt/venv/default/lib/python3.10/site-packages/PIL/Image.py\", line 2193, in resize\n    return self._new(self.im.resize(size, resample, box))\nValueError: height and width must be > 0\n"
     ]
    }
   ],
   "source": [
    "# [\"resnet_18\", \"resnet50\", \"wide_resnet101\", \"resnet152\", \"efficientnet\", \"convnext\", \"vgg\", \"regnet\", \"swin\", \"maxvit\"]\n",
    "for model_name in [\"resnet_18\", \"resnet50\", \"wide_resnet101\", \"resnet152\", \"efficientnet\", \"convnext\", \"vgg\", \"regnet\", \"swin\", \"maxvit\"]:\n",
    "    model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "    data_transforms = {\n",
    "        \"train\": transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.RandomResizedCrop(input_size),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \"valid\": transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "        \"test\": transforms.Compose([\n",
    "            transforms.Resize(input_size),\n",
    "            transforms.CenterCrop(input_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    }\n",
    "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in [\"train\", \"valid\", \"test\"]}\n",
    "    dataloader_dict = {x[0]: torch.utils.data.DataLoader(image_datasets[x[0]], batch_size=batch_size, shuffle=x[1], num_workers=4) for x in [(\"train\", True), (\"valid\", False), (\"test\", False)]}\n",
    "    num_gpus = [i for i in range(torch.cuda.device_count())]\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    if len(num_gpus) > 1:\n",
    "        os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(str(x) for x in num_gpus)\n",
    "        model_ft = torch.nn.DataParallel(model_ft, device_ids=num_gpus)\n",
    "        model_ft = model_ft.module\n",
    "    model_ft = model_ft.to(device)\n",
    "    \n",
    "    params_to_update = model_ft.parameters()\n",
    "    if feature_extract:\n",
    "        params_to_update = []\n",
    "        for name, param in model_ft.named_parameters():\n",
    "            if param.requires_grad == True:\n",
    "                params_to_update.append(param)\n",
    "    \n",
    "    model_lr_map = {\n",
    "        \"resnet_18\": 1e-5,\n",
    "        \"resnet50\": 1e-4, \n",
    "        \"wide_resnet101\": 1e-4, \n",
    "        \"resnet152\": 1e-4, \n",
    "        \"efficientnet\": 1e-4, \n",
    "        \"convnext\": 1e-4, \n",
    "        \"vgg\": 1e-4, \n",
    "        \"regnet\": 1e-4, \n",
    "        \"swin\": 1e-4, \n",
    "        \"maxvit\": 1e-4\n",
    "    }\n",
    "    lr_ = model_lr_map[model_name]\n",
    "    \n",
    "    optimizer_ft = optim.AdamW(params_to_update, lr=lr_)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model_ft = train_model(model_ft, model_name, dataloader_dict, criterion, optimizer_ft, num_classes, num_epochs, False, lr_, df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8435372-0c03-413f-8b68-d4c49e525a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def run_inference_image(path, model):\n",
    "    model.eval()\n",
    "    biopsy_id = os.path.basename(path).split('.')[0]\n",
    "    image = Image.open(path)\n",
    "    \n",
    "    transform_data = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.CenterCrop((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img_t = transform_data(image)\n",
    "    img_t = img_t.float().unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_t)\n",
    "    \n",
    "    prediction = output.squeeze(0).softmax(0)\n",
    "    class_id = prediction.argmax().item()\n",
    "    return biopsy_id, class_id\n",
    "\n",
    "def run_inference(paths, model):\n",
    "    predictions = []\n",
    "    for index in tqdm(range(len(paths)), desc=\"Evaluation Progress\"):\n",
    "        predictions.append(run_inference_image(paths[index], model))\n",
    "    pred_dict = {biopsy: class_id for biopsy, class_id in predictions}\n",
    "    return pred_dict\n",
    "\n",
    "def save_predictions(pred_dict, model_name):\n",
    "    frame = pd.DataFrame()\n",
    "    frame[\"slide_id\"] = list(pred_dict.keys())\n",
    "    frame[\"pred_stage\"] = list(pred_dict.values())\n",
    "    frame.to_csv(\"predictions/predictions_{}_{}.csv\".format(model_name, batch_size))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5d7b066-201e-43a2-9299-963dec90b78b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_model(model_name, num_classes=2):\n",
    "    if model_name == \"resnet18\":\n",
    "        lr = 1e-5\n",
    "        model_ft = resnet18(weights=None)\n",
    "        checkpoints = torch.load(\"saved_models/breast_cancer_resnet_18_1e-05_20_2.pt\")\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        checkpoints = {k: v for k, v in checkpoints.items() if \"fc\" not in k}\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "    \n",
    "    if model_name == \"resnet50\":\n",
    "        lr = 1e-4\n",
    "        model_ft = resnet50(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_resnet50_0.0001_20_2.pt')\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        checkpoints = {k: v for k, v in checkpoints.items() if \"fc\" not in k}\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"resnet152\":\n",
    "        lr = 1e-5\n",
    "        model_ft = resnet152(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_resnet152_0.0001_20_2.pt')\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        checkpoints = {k: v for k, v in checkpoints.items() if \"fc\" not in k}\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "    \n",
    "    if model_name == \"wide_resnet101\":\n",
    "        lr = 1e-4\n",
    "        model_ft = wide_resnet101_2(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_wide_resnet101_0.0001_20_2.pt')\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        checkpoints = {k: v for k, v in checkpoints.items() if \"fc\" not in k}\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"vgg\":\n",
    "        lr = 1e-4\n",
    "        model_ft = vgg19_bn(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_vgg_0.0001_20_2.pt')\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs, num_classes)  # Set to 3 for your case\n",
    "        # This part of the code is important: we are only loading the state_dict for layers\n",
    "        # that match in size, we are ignoring ('skipping') the classifier.6 layer since it doesn't match.\n",
    "        checkpoints = {k: v for k, v in checkpoints.items() if k not in ['classifier.6.weight', 'classifier.6.bias']}\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "    \n",
    "    if model_name == \"efficientnet\":\n",
    "        lr = 4e-4\n",
    "        model_ft = efficientnet_v2_m(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_efficientnet_0.0001_20_2.pt')\n",
    "        num_ftrs = model_ft.classifier[1].in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "    \n",
    "    if model_name == \"convnext\":\n",
    "        lr = 1e-5\n",
    "        model_ft = convnext_base(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_convnext_0.0001_20_2.pt')\n",
    "        num_ftrs = model_ft.classifier[2].in_features\n",
    "        # Redefine the last layer to have 3 outputs instead of 2\n",
    "        model_ft.classifier[2] = nn.Linear(num_ftrs, num_classes) \n",
    "        # Exclude the last layer's weights and bias when loading the checkpoint\n",
    "        checkpoints = {k: v for k, v in checkpoints.items() if k not in ['classifier.2.weight', 'classifier.2.bias']}\n",
    "        # Load the model with strict=False to avoid size mismatch errors\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"regnet\":\n",
    "        lr = 1e-5\n",
    "        model_ft = regnet_x_32gf(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_regnet_0.0001_20_2.pt')\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)  # Redefine the fully connected layer with the correct number of classes\n",
    "        # Exclude the fc.weight and fc.bias when loading the checkpoint\n",
    "        checkpoints = {k: v for k, v in checkpoints.items() if k not in ['fc.weight', 'fc.bias']}\n",
    "        # Load the model with strict=False to avoid size mismatch errors\n",
    "        model_ft.load_state_dict(checkpoints, strict=False)\n",
    "        return model_ft\n",
    "\n",
    "    if model_name == \"swin\":\n",
    "        lr = 1e-5\n",
    "        model_ft = swin_b(weights=None)\n",
    "        checkpoints = torch.load('saved_models/breast_cancer_swin_0.0001_20_3.pt')\n",
    "        num_ftrs = model_ft.head.in_features\n",
    "        model_ft.head = nn.Linear(num_ftrs, num_classes)\n",
    "        model_ft.load_state_dict(checkpoints)\n",
    "        return model_ft\n",
    "\n",
    "    # if model_name == \"maxvit\":\n",
    "    #     lr = 1e-4\n",
    "    #     model_ft = maxvit_t(weights=None)\n",
    "    #     checkpoints = torch.load('best_final_weights/breast_cancer_{}_{}_{}_{}.pt'.format(model_name, batch_size, num_epochs, lr))\n",
    "    #     num_ftrs = model_ft.classifier[5].in_features\n",
    "    #     model_ft.classifier[5] = nn.Linear(num_ftrs, num_classes)\n",
    "    #     model_ft.load_state_dict(checkpoints)\n",
    "    #     return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3502ae0f-866d-40e0-86c8-2e25dc8e423b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_biopsy_id(df, slide_id_value):\n",
    "    # Step 2: Filter rows with the given slide_id\n",
    "    result = df[df['slide_id'] == slide_id_value]\n",
    "    \n",
    "    # Step 3: Extract the corresponding biopsy_id\n",
    "    if not result.empty:\n",
    "        return result['biopsy_id'].iloc[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7b1a812-d9c9-4db2-8d5b-725188563b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_race(df, slide_id_value):\n",
    "    result = df[df[\"slide_id\"] == slide_id_value]\n",
    "    if not result.empty:\n",
    "        return result[\"race\"].iloc[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a509612-3e39-48d9-9e32-891c7d43b599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to group races\n",
    "def group_race(race):\n",
    "    if (race in ['2', '3', '4', '8', '9']) or (race in [2, 3, 4, 5, 8, 9]):\n",
    "        return 'grouped_race'\n",
    "    else:\n",
    "        return race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0036af2-cdb4-4d78-b696-bc83e3bcc913",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ngsci/project/Armin/metadata/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet18\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet50\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide_resnet101\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet152\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregnet\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m to_device(model)\n\u001b[1;32m      5\u001b[0m     data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ngsci/project/Armin/metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(model_name, num_classes)\u001b[0m\n\u001b[1;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n\u001b[1;32m      4\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m resnet18(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m checkpoints \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/breast_cancer_resnet_18_1e-05_20_2.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m num_ftrs \u001b[38;5;241m=\u001b[39m model_ft\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n\u001b[1;32m      7\u001b[0m model_ft\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, num_classes)\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/ngsci/project/Armin/metadata/data.csv\")\n",
    "for model_name in [\"resnet18\", \"resnet50\", \"wide_resnet101\", \"resnet152\", \"vgg\", \"efficientnet\", \"convnext\", \"regnet\"]:\n",
    "    model = build_model(model_name)\n",
    "    model = to_device(model)\n",
    "    data_dir = \"/home/ngsci/project/Armin/metadata\"\n",
    "    test_dir = os.path.join(data_dir, \"test\")\n",
    "    test_image_paths_0 = [os.path.join(test_dir, \"0\", fname) for fname in os.listdir(os.path.join(test_dir, \"0\"))]\n",
    "    test_image_paths_1 = [os.path.join(test_dir, \"1\", fname) for fname in os.listdir(os.path.join(test_dir, \"1\"))]\n",
    "    # Create or overwrite the CSV file\n",
    "    with open('predictions/predictions_{}.csv'.format(model_name), 'w', newline='') as csvfile:\n",
    "        fieldnames = ['biopsy_id', 'slide_id', 'race', 'pred_stage', 'actual_stage']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for path in tqdm(test_image_paths_0, desc=\"Predicting for label 0\"):\n",
    "            prediction = run_inference_image(path, model)\n",
    "            biopsy_id = get_biopsy_id(df, prediction[0])\n",
    "            race = group_race(get_race(df, prediction[0]))\n",
    "            writer.writerow({'biopsy_id': biopsy_id, 'slide_id': prediction[0], 'race': race, 'pred_stage': prediction[1], 'actual_stage': 0})\n",
    "\n",
    "        for path in tqdm(test_image_paths_1, desc=\"Predicting for label 1\"):\n",
    "            prediction = run_inference_image(path, model)\n",
    "            biopsy_id = get_biopsy_id(df, prediction[0])\n",
    "            race = group_race(get_race(df, prediction[0]))\n",
    "            writer.writerow({'biopsy_id': biopsy_id, 'slide_id': prediction[0], 'race': race, 'pred_stage': prediction[1], 'actual_stage': 1})\n",
    "    # pred_dict = run_inference(test_image_paths, model)\n",
    "    # save_predictions(pred_dict, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c53a13c3-a576-4b18-9017-c9c89d2b7427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Function to perform bootstrapping and calculate metrics\n",
    "def bootstrap_metrics(actuals, predictions, n_iterations=50, sample_size=None):\n",
    "    bootstrap_accuracy = []\n",
    "    bootstrap_precision = []\n",
    "    bootstrap_recall = []\n",
    "    bootstrap_f1 = []\n",
    "    \n",
    "    if sample_size is None:\n",
    "        sample_size = len(actuals)\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        # Create a random subsample of the data with replacement\n",
    "        actuals_sample, predictions_sample = resample(actuals, predictions, n_samples=sample_size)\n",
    "        \n",
    "        # Calculate metrics on this subsample\n",
    "        accuracy = accuracy_score(actuals_sample, predictions_sample) * 100\n",
    "        precision = precision_score(actuals_sample, predictions_sample, average=\"weighted\")\n",
    "        recall = recall_score(actuals_sample, predictions_sample, average=\"weighted\")\n",
    "        f1 = f1_score(actuals_sample, predictions_sample, average='weighted')\n",
    "        \n",
    "        # Store the metrics\n",
    "        bootstrap_accuracy.append(accuracy)\n",
    "        bootstrap_precision.append(precision)\n",
    "        bootstrap_recall.append(recall)\n",
    "        bootstrap_f1.append(f1)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    bootstrap_accuracy = np.array(bootstrap_accuracy)\n",
    "    bootstrap_precision = np.array(bootstrap_precision)\n",
    "    bootstrap_recall = np.array(bootstrap_recall)\n",
    "    bootstrap_f1 = np.array(bootstrap_f1)\n",
    "\n",
    "    # Calculate the mean and standard deviation of the bootstrap samples\n",
    "    metrics = {\n",
    "        'accuracy': {'mean': np.mean(bootstrap_accuracy), 'std': np.std(bootstrap_accuracy)},\n",
    "        'precision': {'mean': np.mean(bootstrap_precision), 'std': np.std(bootstrap_precision)},\n",
    "        'recall': {'mean': np.mean(bootstrap_recall), 'std': np.std(bootstrap_recall)},\n",
    "        'f1': {'mean': np.mean(bootstrap_f1), 'std': np.std(bootstrap_f1)}\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8290a345-88d0-48e0-ae27-37b97a7c8f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: resnet18\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 70.62% ± 2.83\n",
      "Bootstrap Precision: 0.76 ± 0.03\n",
      "Bootstrap Recall: 0.71 ± 0.03\n",
      "Bootstrap Weighted F1 Score: 0.73 ± 0.03\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: resnet18\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 55.27% ± 6.33\n",
      "Bootstrap Precision: 0.66 ± 0.10\n",
      "Bootstrap Recall: 0.55 ± 0.06\n",
      "Bootstrap Weighted F1 Score: 0.46 ± 0.08\n",
      "-----------------------------\n",
      "Model Name: resnet50\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 67.37% ± 1.75\n",
      "Bootstrap Precision: 0.77 ± 0.02\n",
      "Bootstrap Recall: 0.67 ± 0.02\n",
      "Bootstrap Weighted F1 Score: 0.71 ± 0.02\n",
      "-----------------------------\n",
      "Model Name: resnet50\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 61.95% ± 4.31\n",
      "Bootstrap Precision: 0.74 ± 0.04\n",
      "Bootstrap Recall: 0.62 ± 0.04\n",
      "Bootstrap Weighted F1 Score: 0.57 ± 0.05\n",
      "-----------------------------\n",
      "Model Name: wide_resnet101\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 58.31% ± 1.66\n",
      "Bootstrap Precision: 0.76 ± 0.02\n",
      "Bootstrap Recall: 0.58 ± 0.02\n",
      "Bootstrap Weighted F1 Score: 0.64 ± 0.02\n",
      "-----------------------------\n",
      "Model Name: wide_resnet101\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 56.72% ± 4.24\n",
      "Bootstrap Precision: 0.57 ± 0.04\n",
      "Bootstrap Recall: 0.57 ± 0.04\n",
      "Bootstrap Weighted F1 Score: 0.57 ± 0.04\n",
      "-----------------------------\n",
      "Model Name: resnet152\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 62.21% ± 1.46\n",
      "Bootstrap Precision: 0.75 ± 0.01\n",
      "Bootstrap Recall: 0.62 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.67 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: resnet152\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 55.96% ± 3.59\n",
      "Bootstrap Precision: 0.57 ± 0.04\n",
      "Bootstrap Recall: 0.56 ± 0.04\n",
      "Bootstrap Weighted F1 Score: 0.55 ± 0.04\n",
      "-----------------------------\n",
      "Model Name: vgg\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 65.84% ± 1.34\n",
      "Bootstrap Precision: 0.76 ± 0.01\n",
      "Bootstrap Recall: 0.66 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.70 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: vgg\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 57.16% ± 2.55\n",
      "Bootstrap Precision: 0.59 ± 0.03\n",
      "Bootstrap Recall: 0.57 ± 0.03\n",
      "Bootstrap Weighted F1 Score: 0.56 ± 0.03\n",
      "-----------------------------\n",
      "Model Name: efficientnet\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 67.34% ± 1.13\n",
      "Bootstrap Precision: 0.76 ± 0.01\n",
      "Bootstrap Recall: 0.67 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.71 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: efficientnet\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 56.38% ± 3.23\n",
      "Bootstrap Precision: 0.58 ± 0.03\n",
      "Bootstrap Recall: 0.56 ± 0.03\n",
      "Bootstrap Weighted F1 Score: 0.55 ± 0.03\n",
      "-----------------------------\n",
      "Model Name: convnext\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 66.91% ± 0.84\n",
      "Bootstrap Precision: 0.77 ± 0.01\n",
      "Bootstrap Recall: 0.67 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.71 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: convnext\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 57.29% ± 1.94\n",
      "Bootstrap Precision: 0.60 ± 0.02\n",
      "Bootstrap Recall: 0.57 ± 0.02\n",
      "Bootstrap Weighted F1 Score: 0.55 ± 0.02\n",
      "-----------------------------\n",
      "Model Name: regnet\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 67.58% ± 0.97\n",
      "Bootstrap Precision: 0.76 ± 0.01\n",
      "Bootstrap Recall: 0.68 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.71 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: regnet\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 56.09% ± 1.96\n",
      "Bootstrap Precision: 0.59 ± 0.02\n",
      "Bootstrap Recall: 0.56 ± 0.02\n",
      "Bootstrap Weighted F1 Score: 0.53 ± 0.02\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "slide_to_race = {}\n",
    "with open('metadata/data.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        slide_to_race[row['slide_id']] = group_race(row['race'])\n",
    "\n",
    "predictions = {}\n",
    "actuals = {}\n",
    "biopsy_ids = {}\n",
    "races = set()\n",
    "\n",
    "for model_name in [\"resnet18\", \"resnet50\", \"wide_resnet101\", \"resnet152\", \"vgg\", \"efficientnet\", \"convnext\", \"regnet\"]:\n",
    "    with open('predictions/predictions_{}.csv'.format(model_name), 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            slide_id = row['slide_id']\n",
    "            if slide_id in slide_to_race.keys():\n",
    "                race = slide_to_race[slide_id]\n",
    "                races.add(race)\n",
    "                if race not in predictions:\n",
    "                    predictions[race] = []\n",
    "                    actuals[race] = []\n",
    "                predictions[race].append(int(row['pred_stage']))\n",
    "                actuals[race].append(int(row['actual_stage']))\n",
    "    \n",
    "    for race in races:\n",
    "        metrics = bootstrap_metrics(actuals[race], predictions[race])\n",
    "        print(f\"Model Name: {model_name}\")\n",
    "        print(f\"Race: {race}\")\n",
    "        print(f\"Bootstrap Accuracy: {metrics['accuracy']['mean']:.2f}% ± {metrics['accuracy']['std']:.2f}\")\n",
    "        print(f\"Bootstrap Precision: {metrics['precision']['mean']:.2f} ± {metrics['precision']['std']:.2f}\")\n",
    "        print(f\"Bootstrap Recall: {metrics['recall']['mean']:.2f} ± {metrics['recall']['std']:.2f}\")\n",
    "        print(f\"Bootstrap Weighted F1 Score: {metrics['f1']['mean']:.2f} ± {metrics['f1']['std']:.2f}\")\n",
    "        print(\"-----------------------------\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa4b103-91bf-43fa-a624-2271e71501af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "resnet18 = pd.read_csv(\"predictions/predictions_resnet18.csv\")\n",
    "resnet50 = pd.read_csv(\"predictions/predictions_resnet50.csv\")\n",
    "resnet152 = pd.read_csv(\"predictions/predictions_resnet152.csv\")\n",
    "efficientnet = pd.read_csv(\"predictions/predictions_efficientnet.csv\")\n",
    "convnext = pd.read_csv(\"predictions/predictions_convnext.csv\")\n",
    "wide_resnet = pd.read_csv(\"predictions/predictions_wide_resnet101.csv\")\n",
    "vgg = pd.read_csv(\"predictions/predictions_vgg.csv\")\n",
    "regnet = pd.read_csv(\"predictions/predictions_regnet.csv\")\n",
    "\n",
    "slide_ids = resnet50.slide_id.tolist()\n",
    "actual_stages = resnet50.actual_stage.tolist()\n",
    "biopsy_ids = resnet50.biopsy_id.tolist()\n",
    "races = resnet50.race.tolist()\n",
    "rest50_preds = resnet50.pred_stage.tolist()\n",
    "efficientnet_preds = efficientnet.pred_stage.tolist()\n",
    "convnext_preds = convnext.pred_stage.tolist()\n",
    "wide_resnet_preds = wide_resnet.pred_stage.tolist()\n",
    "vgg_preds = vgg.pred_stage.tolist()\n",
    "regnet_preds = regnet.pred_stage.tolist()\n",
    "\n",
    "# Using only models that have loss < 1\n",
    "avg_preds = [round((r50 + effnet + convnext_pred + wide_resnet_pred + vgg_pred + regnet_pred )/6)\n",
    "             for r50, effnet, convnext_pred, wide_resnet_pred, vgg_pred, regnet_pred in \n",
    "             zip(rest50_preds, efficientnet_preds, convnext_preds, wide_resnet_preds, vgg_preds, regnet_preds)]\n",
    "\n",
    "final_frame = pd.DataFrame()\n",
    "final_frame['slide_id'] = slide_ids\n",
    "final_frame[\"biopsy_id\"] = biopsy_ids\n",
    "final_frame['pred_stage'] = avg_preds\n",
    "final_frame[\"actual_stage\"] = actual_stages\n",
    "final_frame[\"race\"] = races\n",
    "\n",
    "aggregated_df = final_frame.groupby('biopsy_id').agg({\n",
    "    'pred_stage': 'mean',\n",
    "    'slide_id': 'first',\n",
    "    'actual_stage': 'first',\n",
    "    'race': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Round the mean value to the nearest integer\n",
    "aggregated_df['pred_stage'] = aggregated_df['pred_stage'].round().astype(int)\n",
    "\n",
    "# print(aggregated_df.head())\n",
    "aggregated_df.to_csv('predictions/predictions_final.csv', index=False)\n",
    "# final_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a85a5c6-f38a-4783-9545-627e3fc879e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: regnet\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 62.88% ± 8.76\n",
      "Bootstrap Precision: 0.67 ± 0.09\n",
      "Bootstrap Recall: 0.63 ± 0.09\n",
      "Bootstrap Weighted F1 Score: 0.62 ± 0.09\n",
      "-----------------------------\n",
      "Model Name: regnet\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 29.56% ± 13.26\n",
      "Bootstrap Precision: 0.79 ± 0.34\n",
      "Bootstrap Recall: 0.30 ± 0.13\n",
      "Bootstrap Weighted F1 Score: 0.34 ± 0.18\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "slide_to_race = {}\n",
    "with open('metadata/data.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        slide_to_race[row['slide_id']] = group_race(row['race'])\n",
    "\n",
    "predictions = {}\n",
    "actuals = {}\n",
    "biopsy_ids = {}\n",
    "races = set()\n",
    "\n",
    "with open('predictions/predictions_final.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        slide_id = row['slide_id']\n",
    "        if slide_id in slide_to_race.keys():\n",
    "            race = slide_to_race[slide_id]\n",
    "            races.add(race)\n",
    "            if race not in predictions:\n",
    "                predictions[race] = []\n",
    "                actuals[race] = []\n",
    "            predictions[race].append(int(row['pred_stage']))\n",
    "            actuals[race].append(int(row['actual_stage']))\n",
    "\n",
    "for race in races:\n",
    "    metrics = bootstrap_metrics(actuals[race], predictions[race])\n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    print(f\"Race: {race}\")\n",
    "    print(f\"Bootstrap Accuracy: {metrics['accuracy']['mean']:.2f}% ± {metrics['accuracy']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Precision: {metrics['precision']['mean']:.2f} ± {metrics['precision']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Recall: {metrics['recall']['mean']:.2f} ± {metrics['recall']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Weighted F1 Score: {metrics['f1']['mean']:.2f} ± {metrics['f1']['std']:.2f}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b590b00e-2794-4f9b-8590-78750a037794",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: regnet\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 65.44% ± 8.18\n",
      "Bootstrap Precision: 0.68 ± 0.08\n",
      "Bootstrap Recall: 0.65 ± 0.08\n",
      "Bootstrap Weighted F1 Score: 0.65 ± 0.08\n",
      "-----------------------------\n",
      "Model Name: regnet\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 55.11% ± 16.47\n",
      "Bootstrap Precision: 0.77 ± 0.24\n",
      "Bootstrap Recall: 0.55 ± 0.16\n",
      "Bootstrap Weighted F1 Score: 0.63 ± 0.17\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to group races\n",
    "def group_race(race):\n",
    "    if race in ['2', '3', '4', '8', '9']:\n",
    "        return 'grouped_race'\n",
    "    else:\n",
    "        return race\n",
    "\n",
    "slide_to_race = {}\n",
    "with open('metadata/data.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        slide_to_race[row['slide_id']] = group_race(row['race'])\n",
    "\n",
    "predictions = {}\n",
    "actuals = {}\n",
    "races = set()\n",
    "with open('predictions/predictions_attention.csv') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            slide_id = row['slide_id']\n",
    "            if slide_id in slide_to_race.keys():\n",
    "                race = slide_to_race[slide_id]\n",
    "                races.add(race)\n",
    "                if race not in predictions:\n",
    "                    predictions[race] = []\n",
    "                    actuals[race] = []\n",
    "                predictions[race].append(int(row['pred_stage']))\n",
    "                actuals[race].append(int(row['actual_stage']))\n",
    "\n",
    "for race in races:\n",
    "    metrics = bootstrap_metrics(actuals[race], predictions[race])\n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    print(f\"Race: {race}\")\n",
    "    print(f\"Bootstrap Accuracy: {metrics['accuracy']['mean']:.2f}% ± {metrics['accuracy']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Precision: {metrics['precision']['mean']:.2f} ± {metrics['precision']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Recall: {metrics['recall']['mean']:.2f} ± {metrics['recall']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Weighted F1 Score: {metrics['f1']['mean']:.2f} ± {metrics['f1']['std']:.2f}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6de84bad-ac2d-4a76-b829-ad024ee764c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ngsci/project/Armin/metadata/data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet18\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet50\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide_resnet101\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnet152\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mefficientnet\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconvnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregnet\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 4\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     model \u001b[38;5;241m=\u001b[39m to_device(model)\n\u001b[1;32m      6\u001b[0m     data_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/ngsci/project/Armin/metadata2\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[0;32mIn[40], line 5\u001b[0m, in \u001b[0;36mbuild_model\u001b[0;34m(model_name, num_classes)\u001b[0m\n\u001b[1;32m      3\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n\u001b[1;32m      4\u001b[0m model_ft \u001b[38;5;241m=\u001b[39m resnet18(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 5\u001b[0m checkpoints \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaved_models/breast_cancer_resnet_18_1e-05_20_2.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m num_ftrs \u001b[38;5;241m=\u001b[39m model_ft\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n\u001b[1;32m      7\u001b[0m model_ft\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(num_ftrs, num_classes)\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:809\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    808\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights_only:\n\u001b[1;32m    811\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:1172\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1170\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1171\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1172\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1174\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:1142\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1141\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1142\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:1116\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1112\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39mUntypedStorage)\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m typed_storage \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39mTypedStorage(\n\u001b[0;32m-> 1116\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1117\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1118\u001b[0m     _internal\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typed_storage\u001b[38;5;241m.\u001b[39m_data_ptr() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1121\u001b[0m     loaded_storages[key] \u001b[38;5;241m=\u001b[39m typed_storage\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:217\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 217\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    219\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:182\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 182\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    183\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    184\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice(device):\n",
      "File \u001b[0;32m/opt/venv/default/lib/python3.10/site-packages/torch/serialization.py:166\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    163\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    167\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    168\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    169\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    170\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    171\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "import csv\n",
    "df = pd.read_csv(\"/home/ngsci/project/Armin/metadata/data.csv\")\n",
    "for model_name in [\"resnet18\", \"resnet50\", \"wide_resnet101\", \"resnet152\", \"vgg\", \"efficientnet\", \"convnext\", \"regnet\"]:\n",
    "    model = build_model(model_name, 3)\n",
    "    model = to_device(model)\n",
    "    data_dir = \"/home/ngsci/project/Armin/metadata2\"\n",
    "    test_dir = os.path.join(data_dir, \"test\")\n",
    "    test_image_paths_0 = [os.path.join(test_dir, \"0\", fname) for fname in os.listdir(os.path.join(test_dir, \"0\"))]\n",
    "    test_image_paths_1 = [os.path.join(test_dir, \"1\", fname) for fname in os.listdir(os.path.join(test_dir, \"1\"))]\n",
    "    test_image_paths_2 = [os.path.join(test_dir, \"2\", fname) for fname in os.listdir(os.path.join(test_dir, \"2\"))]\n",
    "    # Create or overwrite the CSV file\n",
    "    with open('predictions/predictions_{}_{}_train.csv'.format(model_name, 3), 'w', newline='') as csvfile:\n",
    "        fieldnames = ['slide_id', 'pred_stage', 'actual_stage', \"biopsy_id\", \"race\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for path in tqdm(test_image_paths_0, desc=\"Predicting for label 0\"):\n",
    "            prediction = run_inference_image(path, model)\n",
    "            biopsy_id = get_biopsy_id(df, prediction[0])\n",
    "            race = group_race(get_race(df, prediction[0]))\n",
    "            writer.writerow({\"biopsy_id\": biopsy_id, 'slide_id': prediction[0], \"race\": race, 'pred_stage': prediction[1], 'actual_stage': 0})\n",
    "\n",
    "        for path in tqdm(test_image_paths_1, desc=\"Predicting for label 1\"):\n",
    "            prediction = run_inference_image(path, model)\n",
    "            biopsy_id = get_biopsy_id(df, prediction[0])\n",
    "            race = group_race(get_race(df, prediction[0]))\n",
    "            writer.writerow({\"biopsy_id\": biopsy_id, 'slide_id': prediction[0], \"race\": race, 'pred_stage': prediction[1], 'actual_stage': 1})\n",
    "        \n",
    "        for path in tqdm(test_image_paths_2, desc=\"Predicting for label 2\"):\n",
    "            prediction = run_inference_image(path, model)\n",
    "            biopsy_id = get_biopsy_id(df, prediction[0])\n",
    "            race = group_race(get_race(df, prediction[0]))\n",
    "            writer.writerow({\"biopsy_id\": biopsy_id, 'slide_id': prediction[0], \"race\": race, 'pred_stage': prediction[1], 'actual_stage': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25a328da-59e5-4a4b-9052-1c4dd7846014",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet18\n",
      "Model Name: resnet18\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 37.50% ± 2.24\n",
      "Bootstrap Precision: 0.36 ± 0.03\n",
      "Bootstrap Recall: 0.38 ± 0.02\n",
      "Bootstrap Weighted F1 Score: 0.34 ± 0.03\n",
      "-----------------------------\n",
      "Model Name: resnet18\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 21.90% ± 1.78\n",
      "Bootstrap Precision: 0.73 ± 0.03\n",
      "Bootstrap Recall: 0.22 ± 0.02\n",
      "Bootstrap Weighted F1 Score: 0.24 ± 0.02\n",
      "-----------------------------\n",
      "resnet50\n",
      "Model Name: resnet50\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 34.35% ± 1.83\n",
      "Bootstrap Precision: 0.40 ± 0.02\n",
      "Bootstrap Recall: 0.34 ± 0.02\n",
      "Bootstrap Weighted F1 Score: 0.36 ± 0.02\n",
      "-----------------------------\n",
      "Model Name: resnet50\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 36.64% ± 1.14\n",
      "Bootstrap Precision: 0.71 ± 0.02\n",
      "Bootstrap Recall: 0.37 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.45 ± 0.01\n",
      "-----------------------------\n",
      "wide_resnet101\n",
      "Model Name: wide_resnet101\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 32.87% ± 1.26\n",
      "Bootstrap Precision: 0.39 ± 0.01\n",
      "Bootstrap Recall: 0.33 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.35 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: wide_resnet101\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 42.13% ± 1.28\n",
      "Bootstrap Precision: 0.71 ± 0.01\n",
      "Bootstrap Recall: 0.42 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.51 ± 0.01\n",
      "-----------------------------\n",
      "resnet152\n",
      "Model Name: resnet152\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 37.70% ± 1.09\n",
      "Bootstrap Precision: 0.43 ± 0.01\n",
      "Bootstrap Recall: 0.38 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.40 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: resnet152\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 43.52% ± 0.94\n",
      "Bootstrap Precision: 0.71 ± 0.01\n",
      "Bootstrap Recall: 0.44 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.52 ± 0.01\n",
      "-----------------------------\n",
      "vgg\n",
      "Model Name: vgg\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 39.95% ± 0.89\n",
      "Bootstrap Precision: 0.43 ± 0.01\n",
      "Bootstrap Recall: 0.40 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.41 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: vgg\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 37.51% ± 0.80\n",
      "Bootstrap Precision: 0.71 ± 0.01\n",
      "Bootstrap Recall: 0.38 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.45 ± 0.01\n",
      "-----------------------------\n",
      "efficientnet\n",
      "Model Name: efficientnet\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 39.09% ± 1.13\n",
      "Bootstrap Precision: 0.42 ± 0.01\n",
      "Bootstrap Recall: 0.39 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.40 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: efficientnet\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 38.04% ± 0.74\n",
      "Bootstrap Precision: 0.70 ± 0.01\n",
      "Bootstrap Recall: 0.38 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.46 ± 0.01\n",
      "-----------------------------\n",
      "convnext\n",
      "Model Name: convnext\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 39.08% ± 0.85\n",
      "Bootstrap Precision: 0.43 ± 0.01\n",
      "Bootstrap Recall: 0.39 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.41 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: convnext\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 38.73% ± 0.70\n",
      "Bootstrap Precision: 0.70 ± 0.01\n",
      "Bootstrap Recall: 0.39 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.47 ± 0.01\n",
      "-----------------------------\n",
      "regnet\n",
      "Model Name: regnet\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 38.66% ± 0.71\n",
      "Bootstrap Precision: 0.43 ± 0.01\n",
      "Bootstrap Recall: 0.39 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.40 ± 0.01\n",
      "-----------------------------\n",
      "Model Name: regnet\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 35.72% ± 0.65\n",
      "Bootstrap Precision: 0.70 ± 0.01\n",
      "Bootstrap Recall: 0.36 ± 0.01\n",
      "Bootstrap Weighted F1 Score: 0.43 ± 0.01\n",
      "-----------------------------\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to group races\n",
    "def group_race(race):\n",
    "    if race in ['2', '3', '4', '5', '8', '9']:\n",
    "        return 'grouped_race'\n",
    "    else:\n",
    "        return race\n",
    "\n",
    "slide_to_race = {}\n",
    "with open('metadata/data.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        slide_to_race[row['slide_id']] = group_race(row['race'])\n",
    "\n",
    "predictions = {}\n",
    "actuals = {}\n",
    "races = set()\n",
    "for model_name in [\"resnet18\", \"resnet50\", \"wide_resnet101\", \"resnet152\", \"vgg\", \"efficientnet\", \"convnext\", \"regnet\"]:\n",
    "    with open('predictions/predictions_{}_3.csv'.format(model_name), 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            slide_id = row['slide_id']\n",
    "            if slide_id in slide_to_race.keys():\n",
    "                race = slide_to_race[slide_id]\n",
    "                races.add(race)\n",
    "                if race not in predictions:\n",
    "                    predictions[race] = []\n",
    "                    actuals[race] = []\n",
    "                predictions[race].append(int(row['pred_stage']))\n",
    "                actuals[race].append(int(row['actual_stage']))\n",
    "\n",
    "\n",
    "    print(model_name)\n",
    "    for race in races:\n",
    "        metrics = bootstrap_metrics(actuals[race], predictions[race])\n",
    "        print(f\"Model Name: {model_name}\")\n",
    "        print(f\"Race: {race}\")\n",
    "        print(f\"Bootstrap Accuracy: {metrics['accuracy']['mean']:.2f}% ± {metrics['accuracy']['std']:.2f}\")\n",
    "        print(f\"Bootstrap Precision: {metrics['precision']['mean']:.2f} ± {metrics['precision']['std']:.2f}\")\n",
    "        print(f\"Bootstrap Recall: {metrics['recall']['mean']:.2f} ± {metrics['recall']['std']:.2f}\")\n",
    "        print(f\"Bootstrap Weighted F1 Score: {metrics['f1']['mean']:.2f} ± {metrics['f1']['std']:.2f}\")\n",
    "        print(\"-----------------------------\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b5ad6ad5-2130-44b9-a12b-732b2401f0db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[2 0 1]\n"
     ]
    }
   ],
   "source": [
    "# [\"resnet18\", \"resnet50\", \"wide_resnet101\", \"resnet152\", \"vgg\", \"efficientnet\", \"convnext\", \"regnet\"]\n",
    "\n",
    "resnet18 = pd.read_csv(\"predictions/predictions_resnet18_3.csv\")\n",
    "resnet50 = pd.read_csv(\"predictions/predictions_resnet50_3.csv\")\n",
    "resnet152 = pd.read_csv(\"predictions/predictions_resnet152_3.csv\")\n",
    "efficientnet = pd.read_csv(\"predictions/predictions_efficientnet_3.csv\")\n",
    "convnext = pd.read_csv(\"predictions/predictions_convnext_3.csv\")\n",
    "wide_resnet = pd.read_csv(\"predictions/predictions_wide_resnet101_3.csv\")\n",
    "vgg = pd.read_csv(\"predictions/predictions_vgg_3.csv\")\n",
    "regnet = pd.read_csv(\"predictions/predictions_regnet_3.csv\")\n",
    "\n",
    "slide_ids = resnet50.slide_id.tolist()\n",
    "actual_stages = resnet50.actual_stage.tolist()\n",
    "biopsy_ids = resnet50.biopsy_id.tolist()\n",
    "races = resnet50.race.tolist()\n",
    "rest18_preds = resnet18.pred_stage.tolist()\n",
    "rest50_preds = resnet50.pred_stage.tolist()\n",
    "rest152_preds = resnet152.pred_stage.tolist()\n",
    "efficientnet_preds = efficientnet.pred_stage.tolist()\n",
    "convnext_preds = convnext.pred_stage.tolist()\n",
    "wide_resnet_preds = wide_resnet.pred_stage.tolist()\n",
    "vgg_preds = vgg.pred_stage.tolist()\n",
    "regnet_preds = regnet.pred_stage.tolist()\n",
    "\n",
    "\n",
    "A = [rest50_preds, efficientnet_preds, convnext_preds, wide_resnet_preds, vgg_preds, regnet_preds, rest18_preds, rest152_preds]\n",
    "\n",
    "# Using only models that have loss < 1\n",
    "avg_preds = [round((r50 + effnet + convnext_pred + wide_resnet_pred + vgg_pred + regnet_pred + rest18_pred + rest152_pred)/8)\n",
    "             for r50, effnet, convnext_pred, wide_resnet_pred, vgg_pred, regnet_pred, rest18_pred, rest152_pred in \n",
    "             zip(rest50_preds, efficientnet_preds, convnext_preds, wide_resnet_preds, vgg_preds, regnet_preds, rest18_preds, rest152_preds)]\n",
    "\n",
    "final_frame = pd.DataFrame()\n",
    "final_frame['slide_id'] = slide_ids\n",
    "final_frame[\"biopsy_id\"] = biopsy_ids\n",
    "final_frame['pred_stage'] = avg_preds\n",
    "final_frame[\"actual_stage\"] = actual_stages\n",
    "final_frame[\"race\"] = races\n",
    "print(final_frame.actual_stage.unique())\n",
    "aggregated_df = final_frame.groupby('biopsy_id').agg({\n",
    "    'pred_stage': 'mean',\n",
    "    'slide_id': 'first',\n",
    "    'actual_stage': 'first',\n",
    "    'race': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Round the mean value to the nearest integer\n",
    "aggregated_df['pred_stage'] = aggregated_df['pred_stage'].round().astype(int)\n",
    "\n",
    "# print(aggregated_df.head())\n",
    "aggregated_df.to_csv('predictions/predictions_final_3.csv', index=False)\n",
    "print(aggregated_df.actual_stage.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c20b0b7-c643-471e-be2f-b30ef8702605",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: regnet\n",
      "Race: 1\n",
      "Bootstrap Accuracy: 56.72% ± 6.26\n",
      "Bootstrap Precision: 0.44 ± 0.08\n",
      "Bootstrap Recall: 0.57 ± 0.06\n",
      "Bootstrap Weighted F1 Score: 0.49 ± 0.07\n",
      "-----------------------------\n",
      "Model Name: regnet\n",
      "Race: grouped_race\n",
      "Bootstrap Accuracy: 69.23% ± 6.41\n",
      "Bootstrap Precision: 0.53 ± 0.08\n",
      "Bootstrap Recall: 0.69 ± 0.06\n",
      "Bootstrap Weighted F1 Score: 0.60 ± 0.08\n",
      "-----------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/venv/default/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to group races\n",
    "def group_race(race):\n",
    "    if race in ['2', '3', '4', '8', '9']:\n",
    "        return 'grouped_race'\n",
    "    else:\n",
    "        return race\n",
    "\n",
    "slide_to_race = {}\n",
    "with open('metadata/data.csv', 'r') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        slide_to_race[row['slide_id']] = group_race(row['race'])\n",
    "\n",
    "predictions = {}\n",
    "actuals = {}\n",
    "races = set()\n",
    "with open('predictions/predictions_final_3.csv') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            slide_id = row['slide_id']\n",
    "            if slide_id in slide_to_race.keys():\n",
    "                race = slide_to_race[slide_id]\n",
    "                races.add(race)\n",
    "                if race not in predictions:\n",
    "                    predictions[race] = []\n",
    "                    actuals[race] = []\n",
    "                predictions[race].append(int(row['pred_stage']))\n",
    "                actuals[race].append(int(row['actual_stage']))\n",
    "\n",
    "for race in races:\n",
    "    metrics = bootstrap_metrics(actuals[race], predictions[race])\n",
    "    print(f\"Model Name: {model_name}\")\n",
    "    print(f\"Race: {race}\")\n",
    "    print(f\"Bootstrap Accuracy: {metrics['accuracy']['mean']:.2f}% ± {metrics['accuracy']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Precision: {metrics['precision']['mean']:.2f} ± {metrics['precision']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Recall: {metrics['recall']['mean']:.2f} ± {metrics['recall']['std']:.2f}\")\n",
    "    print(f\"Bootstrap Weighted F1 Score: {metrics['f1']['mean']:.2f} ± {metrics['f1']['std']:.2f}\")\n",
    "    print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947904e0-9688-4563-b49d-8cb1e44ba7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
